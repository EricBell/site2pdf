content:
  allowed_image_formats:
  - jpg
  - jpeg
  - png
  - gif
  - webp
  include_images: true
  include_menus: false
  include_metadata: true
  remove_images: false
  max_image_size: 10
  min_content_length: 100
crawling:
  follow_external: false
  max_depth: 5
  max_pages: 1000
  request_delay: 2.0
  respect_robots: false
  timeout: 30
directories:
  logs_dir: logs
  output_dir: output
  temp_dir: temp
cache:
  enabled: true
  directory: cache
  compression: true
  compression_level: 6
  max_sessions: 100
  auto_cleanup: true
  cleanup_settings:
    max_age_days: 30
    keep_completed: 10
  save_frequency: 5
  session_timeout_hours: 24
chunking:
  default_max_size: "10MB"
  size_estimation:
    markdown_overhead: 1.2
    pdf_overhead: 2.5
filters:
  exclude_patterns:
  - .*\.pdf$
  - .*\.zip$
  - .*\.exe$
  - /admin/.*
  - /login.*
  - /logout.*
  max_url_length: 2000
  skip_extensions:
  - pdf
  - zip
  - exe
  - dmg
  - pkg
http:
  max_retries: 3
  retry_delay: 5
  use_cookies: true
  user_agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0
human_behavior:
  browsing:
    max_session_pages: 100
    respect_business_hours: false
    robots_respect_probability: 0.8
    session_break_after: 50
    session_break_duration:
    - 30
    - 120
    weekend_factor: 1.2
  delays:
    base_reading_time:
    - 2
    - 8
    complexity_multiplier: 1.5
    fatigue_factor: 0.1
    maximum_delay: 30
    minimum_delay: 0.8
    navigation_decision:
    - 1
    - 3
    variance_percent: 30
  detection_avoidance:
    adaptive_delays: true
    handle_cookies: true
    monitor_rate_limits: true
    realistic_headers: true
    track_referrers: true
logging:
  level: INFO
  log_filename: scraper.log
  log_to_file: true
  rotate_logs: true
markdown:
  include_toc: true
  multi_file: false
  output_filename: scraped_website.md
path_scoping:
  allow_homepage: true
  allow_navigation: limited
  allow_parent_levels: 1
  allow_siblings: true
  enabled: true
  max_external_depth: 1
pdf:
  font:
    family: Arial
    size: 11
  include_page_numbers: true
  include_toc: true
  margins:
    bottom: 20
    left: 15
    right: 15
    top: 20
  output_filename: scraped_website.pdf
  page_size: A4
javascript:
  # JavaScript rendering is DISABLED by default - use --js-render flag to enable
  # Requires Selenium and WebDriver (pip install selenium webdriver-manager)
  # Example: python run.py scrape https://example.com --js-render
  enabled_for_content: false        # Enable browser automation for content rendering
  headless: true                    # Run browser in headless mode (no GUI)
  timeout: 60                       # Page load timeout in seconds (increased for JS-heavy sites)
  implicit_wait: 10                 # Wait time for elements to appear
  browser: auto                     # auto (detect), chrome, or firefox
  window_size: [1920, 1080]        # Browser window size
  additional_wait: 3                # Extra seconds to wait after page load for dynamic content
  handle_infinite_scroll: false     # Detect and handle infinite scroll pages
  max_scroll_attempts: 5            # Maximum scrolls for infinite scroll detection
  debug_screenshots: false          # Save debug screenshots during rendering

authentication:
  # Authentication is DISABLED by default - the scraper works with public pages
  # To enable authentication, use CLI flags: --username, --password, or --auth
  # Example: python run.py scrape https://example.com --username myuser --password mypass
  enabled: false                    # Disable authentication by default (opt-in via CLI)
  cache_sessions: true              # Cache login sessions to avoid re-authentication
  session_duration: "24h"           # How long cached sessions remain valid
  debug_screenshots: true           # Enable debug screenshots during authentication
  method_priority:                  # Authentication method priority order
    - "direct_api"                  # Try direct API calls first (better for automation)
    - "javascript"                  # Then try browser automation
    - "manual"                      # Finally fall back to manual intervention
  sites:                            # Site-specific authentication configuration
    # ideabrowser.com - use direct API method first since browser automation has issues
    ideabrowser.com:
      plugin: "email_otp"           # Use email OTP plugin
      method_priority:              # Override global method priority for this site
        - "direct_api"              # Try direct API first for this site
        - "javascript"              # Then browser automation
        - "manual"                  # Finally manual intervention
    
    # Example site configuration
    # example.com:
    #   plugin: "generic_form"       # Plugin to use (generic_form, github, etc.)
    #   login_url: "/login"          # Login page URL (relative or absolute)
    #   form_selectors:              # CSS selectors for form elements
    #     username_field: "input[name='username']"
    #     password_field: "input[name='password']"
    #     submit_button: "input[type='submit']"
    #     csrf_token: "input[name='_token']"
    #   success_indicators:          # Elements that appear after successful login
    #     - ".user-menu"
    #     - "a[href*='logout']"
    #   failure_indicators:          # Elements that appear after failed login  
    #     - ".error-message"
    #     - ".login-failed"
    #   session_duration: "24h"      # Override default session duration
    #   multi_step_login: false      # Enable for username-first then password flows
